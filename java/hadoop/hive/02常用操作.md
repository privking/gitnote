# HIVE常用操作

# hive hql

### 显示数据库

```sql
show databases;
```

### 使用默认数据库

```sql
use default;
```

### 删除创建的表

```sql
drop table student;
truncate table student;
```

### 创建表并指定分隔符

```sql
create table student(id int,name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
```

### 查询表结构

```sql
show create table student;
```

### 查询库信息

```sql
desc database xxx;
desc database extended xxx; --详细信息
```

### 查询表信息

```sql
desc 表名;
desc formatted 表名;
desc extended 表名;
```

### 创建表

```sql
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
[(col_name data_type [COMMENT col_comment], ...)]   --表中的字段信息
[COMMENT table_comment] --表的注释

[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] 
[CLUSTERED BY (col_name, col_name, ...) 
[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] 

[ROW FORMAT row_format]  --表中数据每行的格式，定义数据字段的分隔符，集合元素的分隔符等

[STORED AS file_format] --表中的数据要以哪种文件格式来存储，默认为TEXTFILE（文本文件）
					    --可以设置为SequnceFile或 Paquret,ORC等
[LOCATION hdfs_path] --表在hdfs上的位置


create table xxx like xxx1;
```

EXTERNAL:  

- 不带EXTERNAL 是一个MANAGED_TABLE （管理表，内部表）
- 带EXTERNAL 是一个外部表
- 内部表(管理表)在执行删除操作时，会将表的元数据(schema)和表位置的数据一起删除！
- 外部表在执行删除表操作时，只删除表的元数据(schema)
- 转换：`alter table p1 set tblproperties('EXTERNAL'='TRUE');`

PARTITIONED BY：

- 在MR中分区概念：在MapTask输出key-value时，为每一个key-value计算一个分区号，同一个分区的数据，会被同一个reduceTask处理，每个分区的数据最终会生成一个结果文件
- HIVE中：将表中的数据，分散到表目录下的多个子目录（分区目录）中
- 意义：为了将数据分散到多个子目录中，在执行查询时，可以只选择某些子目录中的数据，加快查询效率
- 分区查询 `show partitions 表名；`
- 一级分区
  - 创建分区：`alter table 表名 add partition(分区字段名=分区字段值) partition(分区字段名=分区字段值)；`
  - 创建后在hdfs上会生成`分区字段名=分区字段值`的路径
  - 创建后在mysql中 partitions表中生成分区数据
  - 直接使用load向分区加载数据，如果分区不存在，load时会自动生成
  - `load data loacl inpath '/xx/xx/xx' into datble 表名 partition(area='xxx');`
  - 删除分区：`alter table xxx drop partition(area='xxx') , partition(area='xxx')` 管理表会删除数据
- 多级分区：
  - `PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)`
  - `alter table 表名 add partition(分区字段名=分区字段值,分区字段名=分区字段值) partition(分区字段名=分区字段值,分区字段名=分区字段值)；`
  - `load data loacl inpath '/xx/xx/xx' into datble 表名 partition(area='xxx',pp='xxx');`

LOCATION：

- 指定数据位置
- 如果数据已经按照规范格式上传到了hdfs 可以使用分区修复命令 `msck repair table 表名`

CLUSTERED BY &&  SORTED BY

- 指定了 CLUSTERED BY 称为分桶表，把数据分到多个文件中
- 本质也是为了分散数据，在分桶后可以结合hive提供的抽样查询，只查询指定桶的数据
- 如果需要排序 可以加上SORTED BY
- `clustered by (id) sorted by (id desc) into 4 buckets`
- 分桶表导入数据需要运行MR 分桶排序 
- 不能使用load  必须执行insert into
- `insert into 表名 select xxxx`
- 导入数据前 要设置强制分桶 `set hive.enforce.bucketing=true`
- 设置强制排序 `set hive.enforce.sirting=true`
- 抽样查询 `select  *  from 分桶表 tablesample(bucket x of y on 分桶表分桶字段)`
- 抽样查询必须时分桶表
- 假设分了z个桶  x：标识从第几桶开始抽 y: z/y表示抽多少桶  
- y必须是z的因子或倍数  0<x<=y
- 从x桶开始抽，每隔y桶抽一桶 直到抽满 z/y桶

### 查询

```sql
select * from student
```

### 插入

```sql
insert ...
```

### 上传文件

```
# 1. 直接上传到hdfs对应表目录下
# 2. load
load data local inpath '/xxxx/xxx' into table student
```



## 在HIVE CLI模式下

* 可以直接操作hdfs

```sh
hive> dfs -ls /
```

* 操作linux

```sh
hive>!ls /
```

